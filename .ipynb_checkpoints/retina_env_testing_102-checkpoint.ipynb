{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9620ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imagenet_dataset import get_dataset\n",
    "from retina_env import RetinaEnv, calculate_retinal_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d73d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = types.SimpleNamespace()\n",
    "config.batch_size = 32\n",
    "config.margin = 20\n",
    "config.image_h = 224\n",
    "config.image_w = 224\n",
    "config.image_hm = config.image_h+2*config.margin\n",
    "config.image_wm = config.image_w+2*config.margin\n",
    "config.foveate = None\n",
    "config.do_grayscale = True\n",
    "config.history_length = 16\n",
    "config.t_ignore = 16\n",
    "config.t_max =50\n",
    "config.motion_mode = 'velocity'\n",
    "\n",
    "t_vec = np.linspace(0,150,16)\n",
    "\n",
    "balanced_filter = calculate_retinal_filter(t_vec, R=1.0)\n",
    "config.filter = balanced_filter.reshape([1,1,-1,1])\n",
    "config.min_freq = 1\n",
    "config.max_freq = 13\n",
    "config.action_upper_bound = np.array([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9fff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:19:50.499766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Ignoring visible gpu device (device: 1, name: NVIDIA GeForce GT 730, pci bus id: 0000:65:00.0, compute capability: 3.5) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2023-06-05 10:19:50.915803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10247 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bnapp/arivkindNet/neosyclop/imagenet_dataset.py:103: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/home/bnapp/datasets/tensorflow_datasets/imagenet2012/5.0.0/'\n",
    "\n",
    "dataset = get_dataset(dataset_dir,\n",
    "                                     'validation',\n",
    "                                     config.batch_size,\n",
    "                                     image_h = config.image_hm,\n",
    "                                     image_w = config.image_wm,\n",
    "                                     preprocessing='identity',\n",
    "                                     rggb_mode=False,\n",
    "                                     central_squeeze_and_pad_factor=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc9c590",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'action_upper_bound'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16637/3568935938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetinaEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/bnapp/arivkindNet/neosyclop/retina_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, image_generator)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#set size of action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_upper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_upper_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_lower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_upper_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'action_upper_bound'"
     ]
    }
   ],
   "source": [
    "\n",
    "env = RetinaEnv(config,image_generator=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f944afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_game_name = 'gaussian_x1p5'\n",
    "coordinates = np.zeros((config.batch_size,2)) \n",
    "origins_offset = np.array([[config.image_hm//2,config.image_wm//2]])\n",
    "done = False\n",
    "while not done:\n",
    "    action = 10*np.random.normal(size=(config.batch_size,2))\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print('step reward', reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinal_view, cumulative_spectral_density, location_history, timestep = env.unflatten_observation(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f666012",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(retinal_view[-3],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.images[-3],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_history[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d31e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c907929",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(coordinates_history.numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902cd561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
