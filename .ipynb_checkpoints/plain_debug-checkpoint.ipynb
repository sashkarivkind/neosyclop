{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2863c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bnapp/arivkindNet/neosyclop/imagenet_dataset.py:103: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:15:00.174783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Ignoring visible gpu device (device: 1, name: NVIDIA GeForce GT 730, pci bus id: 0000:65:00.0, compute capability: 3.5) with core count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2023-06-05 10:15:00.688667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10247 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:15:02.799948: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:15:04.814436: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'update_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16249/2902351149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_actor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_target' is not defined"
     ]
    }
   ],
   "source": [
    "from imagenet_dataset import get_dataset\n",
    "from retina_env import RetinaEnv, calculate_retinal_filter\n",
    "from rl_networks import create_actor_model, create_critic_model, policy\n",
    "from rl_core import Buffer, update_target\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import types\n",
    "config = types.SimpleNamespace()\n",
    "config.batch_size = 32\n",
    "config.margin = 20\n",
    "config.image_h = 224\n",
    "config.image_w = 224\n",
    "config.image_hm = config.image_h+2*config.margin\n",
    "config.image_wm = config.image_w+2*config.margin\n",
    "config.foveate = None\n",
    "config.do_grayscale = True\n",
    "config.history_length = 16\n",
    "config.t_ignore = 16\n",
    "config.t_max =50\n",
    "config.motion_mode = 'velocity'\n",
    "\n",
    "config.gym_mode = False\n",
    "t_vec = np.linspace(0,150,16)\n",
    "\n",
    "balanced_filter = calculate_retinal_filter(t_vec, R=1.0)\n",
    "config.filter = balanced_filter.reshape([1,1,-1,1])\n",
    "config.min_freq = 1\n",
    "config.max_freq = 13\n",
    "config.action_upper_bound = np.array([2.0, 2.0])\n",
    "\n",
    "dataset_dir = '/home/bnapp/datasets/tensorflow_datasets/imagenet2012/5.0.0/'\n",
    "\n",
    "dataset = get_dataset(dataset_dir,\n",
    "                                     'validation',\n",
    "                                     config.batch_size,\n",
    "                                     image_h = config.image_hm,\n",
    "                                     image_w = config.image_wm,\n",
    "                                     preprocessing='identity',\n",
    "                                     rggb_mode=False,\n",
    "                                     central_squeeze_and_pad_factor=-1)\n",
    "\n",
    "env = RetinaEnv(config, image_generator=dataset)\n",
    "\n",
    "if config.gym_mode:\n",
    "    num_states = env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.shape[0]\n",
    "\n",
    "    upper_bound = env.action_space.high[0]\n",
    "    lower_bound = env.action_space.low[0]\n",
    "else:\n",
    "    num_states = env.observation_size\n",
    "    num_actions = env.action_size\n",
    "    upper_bound = env.action_upper_bound\n",
    "    lower_bound = env.action_lower_bound\n",
    "\n",
    "# You might want to adjust the hyperparameters\n",
    "actor_lr = 0.001\n",
    "critic_lr = 0.002\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "\n",
    "buffer_capacity = 10000\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "\n",
    "# Create actor and critic networks\n",
    "actor_model = create_actor_model(env.image_h, env.image_w, env.spectral_density_size, env.location_history_size, env.timestep_size, env.action_size)\n",
    "critic_model = create_critic_model(env.image_h, env.image_w, env.spectral_density_size, env.location_history_size, env.timestep_size, env.action_size)\n",
    "\n",
    "# Create target actor and critic networks\n",
    "target_actor = create_actor_model(env.image_h, env.image_w, env.spectral_density_size, env.location_history_size, env.timestep_size, env.action_size)\n",
    "target_critic = create_critic_model(env.image_h, env.image_w, env.spectral_density_size, env.location_history_size, env.timestep_size, env.action_size)\n",
    "\n",
    "# Making the weights equal initially\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "# Experience replay buffer\n",
    "buffer = Buffer(buffer_capacity, config.batch_size, num_states=num_states, num_actions=num_actions,\n",
    "                state_reshape_fn=env.unflatten_observation)\n",
    "\n",
    "# Training loop\n",
    "episodes = 100\n",
    "for ep in range(episodes):\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "\n",
    "    while True:\n",
    "        # tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "        action = policy(env.unflatten_observation(prev_state), actor_model, lower_bound, upper_bound)\n",
    "        # Recieve state and reward from environment\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state, action, reward, state))\n",
    "        episodic_reward += reward\n",
    "\n",
    "        buffer.learn(actor_model, target_actor, critic_model, target_critic, actor_optimizer, critic_optimizer, gamma, tau)\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "        # End this episode when `done` is True\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        #prev_state = state avoid assingment by reference:\n",
    "        prev_state = np.copy(state)\n",
    "\n",
    "    print(f\"Episode * {ep} * Episodic Reward is ==> {episodic_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c47a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5299c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.unflatten_observation(prev_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ed52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.retinal_view_size, env.spectral_density_size, env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418149b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
